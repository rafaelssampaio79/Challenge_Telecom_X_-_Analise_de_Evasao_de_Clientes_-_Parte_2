
# üìä Previs√£o de Evas√£o de Clientes - Telecom X

Este projeto tem como objetivo prever a evas√£o de clientes (churn) da empresa fict√≠cia **Telecom X**, utilizando t√©cnicas de Machine Learning e an√°lise de dados.

---

## üß† Desafio

Ap√≥s uma an√°lise explorat√≥ria bem-sucedida na Parte 1, o desafio agora √© construir modelos preditivos capazes de identificar clientes com maior probabilidade de cancelar seus servi√ßos.

---

## üîß Etapas do Projeto

1. **Importa√ß√£o e Explora√ß√£o dos Dados**
   - Carregamento do arquivo `dados_tratados.csv` com dados limpos e padronizados.
   - Verifica√ß√£o de tipos de dados, valores nulos e estat√≠sticas b√°sicas.

2. **Pr√©-processamento**
   - Remo√ß√£o de colunas irrelevantes (`customerID`, `genero`, `telefone_ativo`, `multiplas_linhas`, `tipo_internet`).
   - Codifica√ß√£o de vari√°veis categ√≥ricas com One-Hot Encoding.
   - Normaliza√ß√£o com MinMaxScaler e padroniza√ß√£o com StandardScaler.

3. **An√°lise de Correla√ß√£o**
   - Identifica√ß√£o de vari√°veis com maior correla√ß√£o com a evas√£o (`cancelou`), como `valor_diario`, `mensalidade`, `tipo_contrato`, `tempo_cliente_meses`.

4. **Balanceamento de Classes**
   - Aplica√ß√£o de SMOTE para equilibrar as classes `cancelou` (0, 1, 2).

5. **Modelagem Preditiva**
   - Modelo 1: Regress√£o Log√≠stica (com normaliza√ß√£o).
   - Modelo 2: Random Forest (sem normaliza√ß√£o).

6. **Avalia√ß√£o dos Modelos**
   - M√©tricas: Acur√°cia, Precis√£o, Recall, F1-score, Matriz de Confus√£o.
   - Visualiza√ß√µes: Boxplots, Scatter plots, Heatmaps de correla√ß√£o.

---

## ü§ñ Modelos Utilizados

### üîπ Regress√£o Log√≠stica
- **Justificativa**: Modelo linear, sens√≠vel √† escala, √∫til para interpreta√ß√£o de vari√°veis.
- **Pr√©-processamento**: Normaliza√ß√£o com MinMaxScaler.
- **Resultado**:
  - Acur√°cia: 77.7%
  - Classe 0: Excelente desempenho
  - Classe 2: Razo√°vel
  - Classe 1: N√£o prevista

### üîπ Random Forest
- **Justificativa**: Modelo baseado em √°rvore, robusto e n√£o sens√≠vel √† escala.
- **Pr√©-processamento**: Dados originais sem normaliza√ß√£o.
- **Resultado**:
  - Acur√°cia: 75.2%
  - Classe 0: Forte desempenho
  - Classe 2: Moderado
  - Classe 1: N√£o prevista

---

## üìà An√°lise Comparativa

| M√©trica       | Regress√£o Log√≠stica | Random Forest |
|---------------|---------------------|----------------|
| Acur√°cia      | 77.7%               | 75.2%          |
| Classe 0      | Precision: 0.82 / Recall: 0.90 | Precision: 0.82 / Recall: 0.87 |
| Classe 1      | N√£o prevista        | N√£o prevista   |
| Classe 2      | Precision: 0.61 / Recall: 0.52 | Precision: 0.58 / Recall: 0.50 |

- Ambos os modelos falharam em prever a classe 1, indicando poss√≠vel underfitting ou necessidade de redefini√ß√£o da classe.
- Regress√£o Log√≠stica teve melhor desempenho geral, mas Random Forest foi mais equilibrado.

---

## üìå Conclus√£o

- Vari√°veis como `valor_diario`, `mensalidade`, `tipo_contrato` e `tempo_cliente_meses` s√£o fortes influenciadoras da evas√£o.
- O balanceamento com SMOTE foi essencial para melhorar a representatividade das classes.
- A combina√ß√£o de modelos com e sem normaliza√ß√£o permite avaliar diferentes abordagens e melhorar a robustez da solu√ß√£o.

---

## üöÄ Pr√≥ximos Passos

- Testar modelos mais avan√ßados como XGBoost ou LightGBM.
- Ajustar hiperpar√¢metros para melhorar recall da classe 1.
- Gerar relat√≥rio final com insights estrat√©gicos para reten√ß√£o de clientes.

